{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9518682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import boto3\n",
    "from pprint import pprint as pp\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import writer as wt\n",
    "import os.path\n",
    "from glob import glob\n",
    "from io import StringIO\n",
    "import datetime\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_list = s3_client.list_buckets()\n",
    "bucket_name = 'data-28-final-project-files-group2'\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "folder = \"Data28group2cleanfiles\"\n",
    "\n",
    "name_student_and_trainers = 'All_students_and_trainers'\n",
    "txtfiles = 'Alltxt_to_csv'\n",
    "applicants_filename='Applicantcsvs'\n",
    "#====================================================================================\n",
    "\n",
    "def get_course_date(i):\n",
    "    filename = i['Key']\n",
    "    name = filename.split('/')[1].split('_')\n",
    "    course = '_'.join([name[0], name[1]])\n",
    "    date = name[2].split('.')[0]\n",
    "    #     print(course)\n",
    "    return course, date\n",
    "\n",
    "\n",
    "def get_csvs(client, bucket_name, pref):\n",
    "    \"\"\" Takes in a client and bucket name concatenate all the csvs inside\n",
    "    and return a pandas dataframe\n",
    "    to update :: with an extra column specifying the course title and class\n",
    "    name tutor score score ..... course date\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Given a filename returns the contents of the csv file aws a df\n",
    "    is to be used as a function while looping through all the files\n",
    "    \"\"\"\n",
    "    bucket_contents = client.list_objects(Bucket=bucket_name, Prefix=pref)[\"Contents\"]\n",
    "\n",
    "    academic = pd.DataFrame()\n",
    "\n",
    "    for i in bucket_contents:\n",
    "        course_date = get_course_date(i)\n",
    "        latest_course = client.get_object(Bucket=bucket_name, Key=i[\"Key\"])\n",
    "        a = pd.read_csv(latest_course[\"Body\"])\n",
    "        a['course'] = course_date[0]\n",
    "\n",
    "        a['start_date'] = course_date[1]\n",
    "\n",
    "        academic = pd.concat([academic, a])\n",
    "\n",
    "    return academic\n",
    "\n",
    "\n",
    "def reind(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    To rearrange the columns \n",
    "    \"\"\"\n",
    "    col = list(df.columns)\n",
    "    col.remove('course')\n",
    "    col.remove('start_date')\n",
    "    col.extend(['course', 'start_date'])\n",
    "    df = df.reindex(columns=col)\n",
    "    df['old index'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_csvs_all_courses(client, bucket_name, one_file=True):\n",
    "    \"\"\" Takes in a client and bucket name concatenate all the csvs inside\n",
    "        and return a pandas dataframe\n",
    "        to update :: with an extra column specifying the course title and class\n",
    "        name tutor score score ..... course date\n",
    "        \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Puts it all together and return one dataframe if one_file is Truee (joins all the differnet courses in one dataframe)\n",
    "        returns a list of three data frames ( one for each course) iff one_file is False.\n",
    "        \"\"\"\n",
    "    prefixes = ['Academy/Business', 'Academy/Data', 'Academy/Engineering']\n",
    "    full_list = pd.DataFrame()\n",
    "    files = []\n",
    "    for pref in prefixes:\n",
    "        b = get_csvs(client, bucket_name, pref)\n",
    "        b = reind(b)\n",
    "\n",
    "        if one_file:\n",
    "            full_list = pd.concat([full_list, b])\n",
    "        else:\n",
    "\n",
    "            files.append(b)\n",
    "        print(pref, 'is done')\n",
    "    print('done')\n",
    "    return full_list if one_file else files\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload(client=s3_client, bucket_name=bucket_name, one_file=True, folder=folder,name=name_student_and_trainers):\n",
    "    \n",
    "    \"\"\"\n",
    "    Uploads this code.\n",
    "    uploads onefile if one_file is true other wise upload 3 files(Business,Data,Engineering)\n",
    "    upload()\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    if one_file:\n",
    "        \n",
    "        key=f\"{folder}/{name}.csv\"\n",
    "        dff = get_csvs_all_courses(s3_client,bucket_name,one_file=one_file)\n",
    "        s3_client.put_object(Bucket=bucket_name,Body = dff.to_csv(),Key=key)\n",
    "\n",
    "    else:\n",
    "#   bucket_name,filename,foolder,dum\n",
    "        subjects =  get_csvs_all_courses(s3_client,bucket_name,one_file=False)\n",
    "        filenames=['Business.csv','Data.csv','Engineering.csv']\n",
    "        for i in range(len(filenames)):\n",
    "            key =f\"{folder}/{filenames[i]}\"\n",
    "\n",
    "            print('uploading ',filenames[i])\n",
    "\n",
    "            content=  subjects[i].to_csv()\n",
    "    #         subjects[i].to_csv(filenames[i])\n",
    "            client.put_object(Bucket=bucket_name,Body=subjects[i].to_csv(), Key=key)\n",
    "    return 'done'\n",
    "\n",
    "\n",
    "# =======================================================================\n",
    "# def get_bucket_cont_business():\n",
    "#     contents = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles1/Business\")[\"Contents\"]\n",
    "#     return contents\n",
    "\n",
    "\n",
    "# def get_bucket_cont_data():\n",
    "#     cont_data = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles1/Data\")[\"Contents\"]\n",
    "#     return cont_data\n",
    "\n",
    "\n",
    "# def get_bucket_cont_engineering():\n",
    "#     cont_eng = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles1/Engineering\")[\"Contents\"]\n",
    "#     return cont_eng\n",
    "\n",
    "\n",
    "# def get_body_business():\n",
    "#     for contents in get_bucket_cont_business():\n",
    "#         key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "#         body = pd.read_csv(key[\"Body\"])\n",
    "#         return body\n",
    "\n",
    "\n",
    "# def get_body_data():\n",
    "#     for contents in get_bucket_cont_data():\n",
    "#         data_key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "#         data_body = pd.read_csv(data_key[\"Body\"])\n",
    "#         return data_body\n",
    "\n",
    "\n",
    "# def get_body_engineering():\n",
    "#     for contents in get_bucket_cont_engineering():\n",
    "#         eng_key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "#         eng_body = pd.read_csv(eng_key[\"Body\"])\n",
    "#         return eng_body\n",
    "\n",
    "\n",
    "# def concat_all3files():\n",
    "#     concat3 = pd.DataFrame()\n",
    "#     concat3 = pd.concat([concat3, get_body_business(), get_body_data(), get_body_engineering()])\n",
    "#     return concat3\n",
    "\n",
    "\n",
    "\n",
    "# # pp(concat_all3files())\n",
    "# def send_all_csv_students_to_s3():\n",
    "#     s3_client.put_object(Bucket=bucket_name, Body=concat_all3files().to_csv(), Key='Data28group2cleanfiles/All3Courses.csv')\n",
    "\n",
    "\n",
    "# ====================Compiling the text files===========================\n",
    "\n",
    "def txt_to_df(s3_client, bucket_name, a):\n",
    "    txtfile = s3_client.get_object(Bucket=bucket_name, Key=a[\"Key\"])\n",
    "    txt = txtfile['Body'].read()\n",
    "    txt = txt.decode('utf-8')\n",
    "    txt = txt.replace('\\r', '')\n",
    "    txt = txt.replace('Psychometrics: ', ',')\n",
    "    txt = txt.replace('Presentation: ', '').strip()\n",
    "    txt_list = txt.split('\\n')\n",
    "    inter_day = txt_list[0]\n",
    "    inter_uni = txt_list[1]\n",
    "    txt_fi = txt_list[3:]\n",
    "\n",
    "    col = ['name', 'Psychometrics', 'Presentation', 'Date of test', 'Academy']\n",
    "    inter_day = datetime.datetime.strptime(inter_day, '%A %d %B %Y')\n",
    "    new_txt_fi = []\n",
    "    for i in txt_fi:\n",
    "        b = i.split(',')\n",
    "        b[0] = b[0].strip(' ').strip('-').strip(' ')\n",
    "        new_txt_fi.append(','.join(b))\n",
    "    new_txt_fi_2 = []\n",
    "    for i in new_txt_fi:\n",
    "        dummy = i.split(',')\n",
    "        dummy.append(str(inter_day))  # i changed this to string and added an import datetime at the top\n",
    "        dummy.append(inter_uni)\n",
    "        new_txt_fi_2.append(dummy)\n",
    "\n",
    "    txt_df = pd.DataFrame(new_txt_fi_2)\n",
    "    txt_df.columns = col\n",
    "    del txt\n",
    "    del txt_list\n",
    "    del txt_fi\n",
    "    del new_txt_fi\n",
    "    return txt_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def upload_alltxt_as_csv(s3_client=s3_client, bucket_name=bucket_name, key=f'{folder}/{txtfiles}.csv'):\n",
    "    bucket_cont = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Talent/Sparta Day\")[\"Contents\"]\n",
    "    all_df = pd.DataFrame()\n",
    "    for a in bucket_cont:\n",
    "        dummy = txt_to_df(s3_client, bucket_name, a)\n",
    "        all_df = pd.concat([all_df, dummy])\n",
    "    all_df['old index'] = all_df.index\n",
    "    all_df = all_df.reset_index(drop=True)\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=all_df.to_csv(), Key=key)\n",
    "    return 'done'\n",
    "\n",
    "\n",
    "# ===============Functions to upload The applicants data=======================================\n",
    "\n",
    "def get_all_files_folder(s3_client, bucket_name, folder):\n",
    "    \"\"\" This function gets all the files from a folder\"\"\"\n",
    "    paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "    response = paginator.paginate(Bucket=bucket_name, Prefix=folder, PaginationConfig={\"MaxItems\": 6000})\n",
    "    fij = []\n",
    "    for page in response:\n",
    "        #     print(\"getting 2 files from S3\")\n",
    "        files = page.get(\"Contents\")\n",
    "        for file in files:\n",
    "            #         print(f\"file_name: {file['Key']}, size: {file['Size']}\")\n",
    "            fij.append(file)\n",
    "    return fij\n",
    "\n",
    "\n",
    "def Application_csv(s3_client, bucket_name):\n",
    "    #     loops through the pages and get all files filter them and get all csv as a dataframe\n",
    "    def filter_applicants(x):\n",
    "        if x['Key'].endswith('Applicants.csv'):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def clean_degree(x):\n",
    "        x = str(x)\n",
    "        c = x.strip().split(':')\n",
    "        if len(c) > 1:\n",
    "            c = '.'.join(c)\n",
    "        else:\n",
    "            c = c[0][0]\n",
    "        return (c)\n",
    "\n",
    "    def clean(x):\n",
    "        x = str(x)\n",
    "        x = re.sub('-|\\(|\\)|\\s', '', x)\n",
    "        return str(x)\n",
    "\n",
    "    key = 'Talent'\n",
    "    bucket_content_name = get_all_files_folder(s3_client, bucket_name, 'Talent')\n",
    "    bucket_content_name = [i for i in bucket_content_name if filter_applicants(i)]\n",
    "    applications = pd.DataFrame()\n",
    "\n",
    "    for i in bucket_content_name:\n",
    "        monthly_application = s3_client.get_object(Bucket=bucket_name, Key=i[\"Key\"])\n",
    "        a = pd.read_csv(monthly_application[\"Body\"])\n",
    "        a['Filename'] = i['Key'].split('/')[1].split('.')[0]  # new column\n",
    "\n",
    "        applications = pd.concat([applications, a])\n",
    "\n",
    "    applications['degree'] = applications['degree'].apply(clean_degree)\n",
    "    applications['phone_number'] = applications['phone_number'].apply(clean)\n",
    "    return applications\n",
    "\n",
    "\n",
    "def upload_applicants(filename=f'{folder}/{applicants_filename}.csv'):\n",
    "    # upload the df gotten from applicants to a particular filename\n",
    "    df = Application_csv(s3_client, bucket_name)\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=df.to_csv(), Key=filename)\n",
    "    return 'done'\n",
    "\n",
    "#------------ json extraction -------------------------------------------------------------------\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_list = s3_client.list_buckets()\n",
    "bucket_name = 'data-28-final-project-files-group2'\n",
    "bucket_contents = s3_client.list_objects_v2(Bucket='data-28-final-project-files-group2', Prefix='Talent')[\"Contents\"]\n",
    "paginator = s3_client.get_paginator('list_objects_v2')\n",
    "\n",
    "op_param = {'Bucket': 'data-28-final-project-files-group2',\n",
    "            'Prefix': 'Talent'}\n",
    "page_iter = paginator.paginate(**op_param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_data():\n",
    "    combined_data = pd.DataFrame()\n",
    "    for page in page_iter:\n",
    "        for content in page['Contents']:\n",
    "            if content['Key'].endswith('.json'):\n",
    "                result_json = content['Key']\n",
    "                s3_object = s3_client.get_object(Bucket=bucket_name, Key=result_json)\n",
    "                data = json.load(s3_object['Body'])  # returns contents of file as dictionary\n",
    "                data_df = pd.DataFrame.from_dict(data, orient='index').T  # from dictionary converts to dataframe\n",
    "                data_df['id'] = content['Key'].split('/')[1].split('.')[0] #adds if from the file name\n",
    "                combined_data = pd.concat([combined_data, data_df], axis=0)  # adds data onto the dataframe\n",
    "                combined_data.to_csv(\"final_json_all.csv\", encoding='utf-8', index=False)  # converts data to csv\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "all_json='Jsons_to_CSV'\n",
    "def send_all_json():\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=extract_data(), Key=f'{folder}/{all_json}.csv')\n",
    "    \n",
    "\n",
    "# import boto3\n",
    "# from pprint import pprint as pp\n",
    "# import json\n",
    "# import pandas as pd\n",
    "# import csv\n",
    "# from csv import writer as wt\n",
    "# import os.path\n",
    "# from glob import glob\n",
    "\n",
    "# s3_client=boto3.client('s3')\n",
    "\n",
    "# bucket_list = s3_client.list_buckets()\n",
    "# bucket_name = 'data-28-final-project-files-group2'\n",
    "\n",
    "#These first 3 functions gets the contents from all 3 files.\n",
    "\n",
    "def get_bucket_cont_business():\n",
    "    contents = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Allcsv/Business\")[\"Contents\"]\n",
    "    return contents\n",
    "\n",
    "\n",
    "def get_bucket_cont_data():\n",
    "    cont_data = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Allcsv/data\")[\"Contents\"]\n",
    "    return cont_data\n",
    "\n",
    "\n",
    "def get_bucket_cont_engineering():\n",
    "    cont_eng = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Allcsv/Engineering\")[\"Contents\"]\n",
    "    return cont_eng\n",
    "\n",
    "#These next 3 extracts the body from all 3 file contents.\n",
    "\n",
    "def get_body_business():\n",
    "    for contents in get_bucket_cont_business():\n",
    "        key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "        body = pd.read_csv(key[\"Body\"])\n",
    "        return body\n",
    "\n",
    "\n",
    "\n",
    "def get_body_data():\n",
    "    for stuff in get_bucket_cont_data():\n",
    "        data_key = s3_client.get_object(Bucket=bucket_name, Key=stuff[\"Key\"])\n",
    "        data_body = pd.read_csv(data_key[\"Body\"])\n",
    "        return data_body\n",
    "\n",
    "\n",
    "\n",
    "def get_body_engineering():\n",
    "    for things in get_bucket_cont_engineering():\n",
    "        eng_key = s3_client.get_object(Bucket=bucket_name, Key=things[\"Key\"])\n",
    "        eng_body = pd.read_csv(eng_key[\"Body\"])\n",
    "        return eng_body\n",
    "\n",
    "\n",
    "#This file concatenates all 3 bodies together into an empty dataframe.\n",
    "\n",
    "def concat_all3files():\n",
    "    concat3 = pd.DataFrame()\n",
    "    concat3 = pd.concat([concat3, get_body_business(), get_body_data(), get_body_engineering()])\n",
    "    return concat3\n",
    "\n",
    "#This function replaces all the empty cells with the number '0', in order for SQL to read the csv file easier.\n",
    "\n",
    "def change_empty_cells():\n",
    "    new_file = concat_all3files().fillna(0)\n",
    "    return new_file\n",
    "\n",
    "#These next functions removes the first and last columns as they are redundant.\n",
    "\n",
    "def delete_first_column():\n",
    "    df= change_empty_cells()\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def delete_last_column():\n",
    "    df =delete_first_column()\n",
    "    df.drop(columns=df.columns[-1], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "#This function turns the dataframe into a csv.\n",
    "\n",
    "def dataframe_to_csv():\n",
    "    new_file = delete_last_column().to_csv(header=False, index=False)\n",
    "    return new_file\n",
    "\n",
    "#Finally, this function sends the file back to S3, and if the file already exists then it just updates the existing file.\n",
    "def send_all_csv_students_to_s3():\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=dataframe_to_csv(), Key='Data28group2cleanfiles/all3concat.csv')\n",
    "\n",
    "#This just calls the previous function.\n",
    "\n",
    "send_all_csv_students_to_s3()\n",
    "\n",
    "\n",
    "#Here we fix reformat the SpartaTestDay, Applicants and Talents CSV files.\n",
    "#First we extract all 3 from their respective folders.\n",
    "def get_bucket_cont_all_txt():\n",
    "    contents = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles/Alltxt_to_csv\")[\"Contents\"]\n",
    "    return contents\n",
    "\n",
    "\n",
    "def get_bucket_cont_final_json():\n",
    "    cont_data = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles/FinalJsonFile\")[\"Contents\"]\n",
    "    return cont_data\n",
    "\n",
    "\n",
    "def get_bucket_cont_applicants():\n",
    "    cont_data = s3_client.list_objects(Bucket=bucket_name, Prefix=\"Data28group2cleanfiles/Applicantcsvs\")[\"Contents\"]\n",
    "    return cont_data\n",
    "\n",
    "#Then we extract the bodies from all 3 and place them in 3 seperate dataframes\n",
    "\n",
    "def get_body_all_txt():\n",
    "    df = pd.DataFrame()\n",
    "    for contents in get_bucket_cont_all_txt():\n",
    "        key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "        body = pd.read_csv(key[\"Body\"])\n",
    "        df = pd.concat([df, body])\n",
    "        return df\n",
    "\n",
    "\n",
    "def get_body_final_json():\n",
    "    df = pd.DataFrame()\n",
    "    for contents in get_bucket_cont_final_json():\n",
    "        key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "        body = pd.read_csv(key[\"Body\"])\n",
    "        df = pd.concat([df, body])\n",
    "        return df\n",
    "\n",
    "\n",
    "def get_body_applicants():\n",
    "    df = pd.DataFrame()\n",
    "    for contents in get_bucket_cont_applicants():\n",
    "        key = s3_client.get_object(Bucket=bucket_name, Key=contents[\"Key\"])\n",
    "        body = pd.read_csv(key[\"Body\"])\n",
    "        df = pd.concat([df, body])\n",
    "        return df\n",
    "\n",
    "#Now, we get rid of the unnecessary columns and headers\n",
    "\n",
    "def fix_all_txt_1st_column():\n",
    "     df = get_body_all_txt()\n",
    "     df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "     return df\n",
    "\n",
    "def fix_applicants_1st_column():\n",
    "    df = get_body_applicants()\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_applicants_2nd_column():\n",
    "    df = fix_applicants_1st_column()\n",
    "    df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_all_txt_last_column():\n",
    "    df = fix_all_txt_1st_column()\n",
    "    df.drop(columns=df.columns[-1], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_applicants_last_column():\n",
    "    df = fix_applicants_2nd_column()\n",
    "    df.drop(columns=df.columns[-1], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fix_json_last_column():\n",
    "    df = get_body_final_json()\n",
    "    df.drop(columns=df.columns[-1], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fix_all_txt_header():\n",
    "    new_file = fix_all_txt_last_column().to_csv(header=False, index=False)\n",
    "    return new_file\n",
    "\n",
    "def fix_json_header():\n",
    "    new_file = fix_json_last_column().to_csv(header=False, index=False)\n",
    "    return new_file\n",
    "\n",
    "def fix_applicants_header():\n",
    "    new_file = fix_applicants_last_column().to_csv(header=False, index=False)\n",
    "    return new_file\n",
    "\n",
    "#Finally, we send the fixed files back to the same folder using their correct file names.\n",
    "\n",
    "\n",
    "\n",
    "def send_new_txt_s3():\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=fix_all_txt_header(), Key='Data28group2cleanfiles/SpartaTestDay.csv')\n",
    "\n",
    "def send_new_json_s3():\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=fix_json_header(), Key='Data28group2cleanfiles/Talent.csv')\n",
    "\n",
    "send_new_json_s3()\n",
    "def send_new_json_s3():\n",
    "    s3_client.put_object(Bucket=bucket_name, Body=fix_applicants_header(), Key='Data28group2cleanfiles/Applicants.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f893f0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academy/Business is done\n",
      "Academy/Data is done\n",
      "Academy/Engineering is done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "upload()  ## csv for students and trainers\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea71d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_alltxt_as_csv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fa4dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_applicants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b9f055",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Body, value:                  name        date  \\\n0   Stillmann Castano  22/08/2019   \n0     Hilary Willmore  01/08/2019   \n0       Efrem Whipple  22/08/2019   \n0         Sydel Fenne  28/08/2019   \n0     Michel Lebarree  07/08/2019   \n..                ...         ...   \n0     Jacky Reilingen  04/04/2019   \n0     Phillis Lyfield  10/04/2019   \n0        Celle Barlas  16/04/2019   \n0          Scott Duny  11/04/2019   \n0   Boycey Matushenko  25/04/2019   \n\n                                      tech_self_score  \\\n0       {'C#': 6, 'Java': 5, 'R': 2, 'JavaScript': 2}   \n0         {'Python': 1, 'C#': 4, 'Java': 2, 'C++': 4}   \n0                               {'Ruby': 4, 'C++': 4}   \n0                              {'Java': 3, 'SPSS': 4}   \n0   {'Python': 3, 'Java': 4, 'Ruby': 1, 'R': 2, 'P...   \n..                                                ...   \n0             {'C#': 2, 'Java': 6, 'R': 1, 'SPSS': 4}   \n0           {'C#': 4, 'Java': 4, 'Ruby': 4, 'PHP': 1}   \n0                 {'R': 2, 'C++': 1, 'JavaScript': 4}   \n0                                         {'Ruby': 3}   \n0         {'Python': 2, 'C#': 3, 'Java': 3, 'C++': 4}   \n\n                                     strengths  \\\n0                                   [Charisma]   \n0          [Patient, Curious, Problem Solving]   \n0            [Courteous, Independent, Patient]   \n0                                 [Passionate]   \n0                                  [Versatile]   \n..                                         ...   \n0                                  [Versatile]   \n0      [Organisation, Independent, Determined]   \n0                            [Problem Solving]   \n0   [Reliable, Perfectionism, Problem Solving]   \n0                                [Independent]   \n\n                                weaknesses self_development geo_flex  \\\n0     [Distracted, Impulsive, Introverted]              Yes      Yes   \n0       [Overbearing, Chatty, Indifferent]               No      Yes   \n0        [Introverted, Impulsive, Anxious]              Yes      Yes   \n0               [Perfectionist, Sensitive]              Yes      Yes   \n0     [Controlling, Perfectionist, Chatty]              Yes      Yes   \n..                                     ...              ...      ...   \n0   [Indifferent, Intolerant, Introverted]              Yes       No   \n0      [Sensitive, Overbearing, Impatient]              Yes      Yes   \n0                               [Critical]              Yes      Yes   \n0                               [Stubborn]              Yes      Yes   \n0                  [Controlling, Stubborn]              Yes      Yes   \n\n   financial_support_self result course_interest     id  \n0                     Yes   Pass        Business  10383  \n0                     Yes   Fail            Data  10384  \n0                     Yes   Pass        Business  10385  \n0                     Yes   Pass            Data  10386  \n0                     Yes   Pass     Engineering  10387  \n..                    ...    ...             ...    ...  \n0                     Yes   Fail        Business  13483  \n0                     Yes   Pass     Engineering  13484  \n0                     Yes   Pass     Engineering  13485  \n0                     Yes   Pass            Data  13486  \n0                      No   Fail     Engineering  13487  \n\n[3105 rows x 11 columns], type: <class 'pandas.core.frame.DataFrame'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17012/935590452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msend_all_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17012/1504101408.py\u001b[0m in \u001b[0;36msend_all_json\u001b[1;34m()\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msend_all_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0ms3_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextract_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Data28group2cleanfiles/Jsons_to_CSV.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    414\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m             \u001b[1;34m'auth_type'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m         }\n\u001b[1;32m--> 715\u001b[1;33m         request_dict = self._convert_to_request_dict(\n\u001b[0m\u001b[0;32m    716\u001b[0m             api_params, operation_model, context=request_context)\n\u001b[0;32m    717\u001b[0m         \u001b[0mresolve_checksum_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[1;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[0;32m    763\u001b[0m         api_params = self._emit_api_params(\n\u001b[0;32m    764\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m--> 765\u001b[1;33m         request_dict = self._serializer.serialize_to_request(\n\u001b[0m\u001b[0;32m    766\u001b[0m             api_params, operation_model)\n\u001b[0;32m    767\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[1;34m(self, parameters, operation_model)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                                     operation_model.input_shape)\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[0;32m    361\u001b[0m                                                      operation_model)\n",
      "\u001b[1;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Body, value:                  name        date  \\\n0   Stillmann Castano  22/08/2019   \n0     Hilary Willmore  01/08/2019   \n0       Efrem Whipple  22/08/2019   \n0         Sydel Fenne  28/08/2019   \n0     Michel Lebarree  07/08/2019   \n..                ...         ...   \n0     Jacky Reilingen  04/04/2019   \n0     Phillis Lyfield  10/04/2019   \n0        Celle Barlas  16/04/2019   \n0          Scott Duny  11/04/2019   \n0   Boycey Matushenko  25/04/2019   \n\n                                      tech_self_score  \\\n0       {'C#': 6, 'Java': 5, 'R': 2, 'JavaScript': 2}   \n0         {'Python': 1, 'C#': 4, 'Java': 2, 'C++': 4}   \n0                               {'Ruby': 4, 'C++': 4}   \n0                              {'Java': 3, 'SPSS': 4}   \n0   {'Python': 3, 'Java': 4, 'Ruby': 1, 'R': 2, 'P...   \n..                                                ...   \n0             {'C#': 2, 'Java': 6, 'R': 1, 'SPSS': 4}   \n0           {'C#': 4, 'Java': 4, 'Ruby': 4, 'PHP': 1}   \n0                 {'R': 2, 'C++': 1, 'JavaScript': 4}   \n0                                         {'Ruby': 3}   \n0         {'Python': 2, 'C#': 3, 'Java': 3, 'C++': 4}   \n\n                                     strengths  \\\n0                                   [Charisma]   \n0          [Patient, Curious, Problem Solving]   \n0            [Courteous, Independent, Patient]   \n0                                 [Passionate]   \n0                                  [Versatile]   \n..                                         ...   \n0                                  [Versatile]   \n0      [Organisation, Independent, Determined]   \n0                            [Problem Solving]   \n0   [Reliable, Perfectionism, Problem Solving]   \n0                                [Independent]   \n\n                                weaknesses self_development geo_flex  \\\n0     [Distracted, Impulsive, Introverted]              Yes      Yes   \n0       [Overbearing, Chatty, Indifferent]               No      Yes   \n0        [Introverted, Impulsive, Anxious]              Yes      Yes   \n0               [Perfectionist, Sensitive]              Yes      Yes   \n0     [Controlling, Perfectionist, Chatty]              Yes      Yes   \n..                                     ...              ...      ...   \n0   [Indifferent, Intolerant, Introverted]              Yes       No   \n0      [Sensitive, Overbearing, Impatient]              Yes      Yes   \n0                               [Critical]              Yes      Yes   \n0                               [Stubborn]              Yes      Yes   \n0                  [Controlling, Stubborn]              Yes      Yes   \n\n   financial_support_self result course_interest     id  \n0                     Yes   Pass        Business  10383  \n0                     Yes   Fail            Data  10384  \n0                     Yes   Pass        Business  10385  \n0                     Yes   Pass            Data  10386  \n0                     Yes   Pass     Engineering  10387  \n..                    ...    ...             ...    ...  \n0                     Yes   Fail        Business  13483  \n0                     Yes   Pass     Engineering  13484  \n0                     Yes   Pass     Engineering  13485  \n0                     Yes   Pass            Data  13486  \n0                      No   Fail     Engineering  13487  \n\n[3105 rows x 11 columns], type: <class 'pandas.core.frame.DataFrame'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object"
     ]
    }
   ],
   "source": [
    "send_all_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ec160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
